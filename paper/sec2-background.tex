\section{Background Survey}
\label{sec:survey}

In our efforts to provide a means to verify information/images and ultimately tackle the deepfake problem that persists today, we present two use cases: the case for source confidentiality and the case for authenticity.

\subsection{The Case for Confidentiality}
News and media outlets excessively use "anonymous sources" to protect the confidentiality of outside party involvement in reports. However, contrary to popular belief, best journalistic practices and ethics state that source anonymity should only be used when necessary. These ethics deemed the identification of sources to provide the readers a way to gauge the source's credibility and the information \cite{wulfemeyer83}. Furthermore, those publications that inordinately cited \enquote{anonymous sources} were seen as lazy and undermined the legitimacy of such information gathering as a tool.

With the nearly limitless capabilities of the worldwide web, achieving source anonymity is almost impossible. The maturation and continued technological advancement consistently present the possibility that an individual's life could be (and has been) significantly and negatively impacted by perceived slights or affiliations with specific groups \cite{svana18}). In this technological age, confidentiality and privacy have never been more prized, yet so easily subverted \cite{svana18, durity05}. Frameworks exist that provide sharing pathways where the pathways do not identify the users \cite{cvppfr19, tccn13}. Tangentially, we sought to create a system that provides confidentiality to the source (if desired or needed) while allowing the reporter or any other third party to authenticate the originality and volume of edits done to the piece of media (the primary use case being digital photographs).

\subsection{The Case for Authenticity}
The proliferation of "deepfakes" in the media has created a need for any third party to take a piece of media and use it to check the provenance thoroughly \cite{ckdg20}. Specifically, in \cite{ckdg20}, a decentralized blockchain adds an object to its ledger after determining the hash of the discriminative features of the object (calculated using multiple LSTMs \cite{lstm}). This encoding of digital objects into discriminative features is similar to ARCHANGEL \cite{archangel}, a decentralized blockchain-based system for guaranteeing the integrity of archives of digital objects. However, these approaches are specific to particular digital objects (e.g., video frames) and do not provide a mechanism for authenticating the users sharing a digital object. 

Provenance and edit checking is available to experts in their related fields \cite{cooper10}, but it may be unusable or impractical for journalists or, say, art experts who want to know that they are buying authentic digital art \cite{wlwc21}. In addition, other mechanisms (including blockchain, e.g., \cite{qqjs19}) address fake news using a verification framework that involves all the actors (the source, the publisher, and the reader). This work builds on the theoretical framework for building trust and curbing fake news \cite{hw17, sllj18, jm19}. More specifically, \cite{qqjs19} proposes a blockchain-based framework that (1) allows publishers to distinguish between authentic sources and fake sources, (2) adopts a smart-contract \cite{smart-contract} to publish news articles, and (3) ensures the integrity of published articles through the use of semantic similarity search (e.g., \cite{sshash-1,sshash-2}). Verification of a news article can be determined by searching the news stored in a Merkle tree \cite{merkle-tree}.